import tensorflow as tf
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
import numpy as np
import math
from tensorflow import keras
from tensorflow.keras import layers
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression
from sklearn.datasets import make_classification
from sklearn.model_selection import cross_val_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score

SubjectInfo = pd.read_csv("/Users/lannacaruth/Documents/ads_subj_lelvel_metadata_csv.csv")
SubjectInfoInclude = SubjectInfo[SubjectInfo["COMPLEFL"]== "Y"] #remove subjects who were marked as not having completed the study
#remove dates and communication
SubjectInfoInclude.drop(["DOB","BASEDT","INFCDT","ELIGFL","ELIGDT","NOCONT","NOCNTOTH","SCRDT","MO2DT","MO4DT","MO6DT","MO8DT","MO10DT","MO12DT","PTPVDT","PTSVDT","PMO3DT","PMO6DT","COMPLEDT","DSREASCD","DSREAS","DSSPEC","LASTDT","DSCOMM"],axis=1,inplace=True)
SubjectInfoInclude.shape

SiteLevelInfo = pd.read_excel("/Users/lannacaruth/Downloads/adpd_periodontal data.xlsx") #one record per subject per visit per tooth per tooth site
SiteLevelInfoInclude = SiteLevelInfo[SiteLevelInfo["VISITN"]==0]

#select obly subject id , vist number, median pocket depth, tooth missing flags, abcess flags, tooth number, and bleeding on probing flags
toothnumbers = SiteLevelInfo["TOQT"].unique()
SiteLevelInfoIncludeClinStats = SiteLevelInfoInclude[["SUBJID","ID","VISITN","PDEP","TOMISSFN","ABCESSFN","TOQT","BOPFN"]] 
#for each id
#count values in column that are not empty
#take that number and put it in a seperate column
MouthLevelInfoIncludeClinStats = SiteLevelInfoIncludeClinStats[["SUBJID","ID"]]

SubjectProgressionInfo = pd.read_excel("/Users/lannacaruth/Downloads/Subj_level_PDClass_ProgressionClass.xlsx")
#remove index and initial classification columns
SubjectProgressionInfo.drop(["Obs","PDCLASS"],axis=1,inplace=True)
#match naming and type converntions in subject level data frame
SubjectProgressionInfo.rename(columns={"subjid":"SUBJID","progclass":"PROGCLASS"},inplace=True)
SubjectProgressionInfo["SUBJID"] = SubjectProgressionInfo["SUBJID"].astype(object)

FullSubjectLevelInfo  = pd.merge(SubjectInfoInclude,SubjectProgressionInfo,how="outer",on="SUBJID")
FullSubjectLevelInfo.nunique()

# should i drop ids with no prog class are there other files ??
FullSubjectLevelInfo["PROGCLASS"].count()
#FinalCLinData = pd.merge(FullSubjectLevelInfo,SiteLevelInfoIncludeClinStats,how="outer",on="SUBJID")

tomissfn ={}
abcessfn ={}
bopfn ={}

for ID in FullSubjectLevelInfo["SUBJID"]: 
    missingteeth = 0
    abcesses = 0
    bleedingteeth = 0
    for tnum in toothnumbers:
       tnumdf = SiteLevelInfoIncludeClinStats.loc[(SiteLevelInfoIncludeClinStats["SUBJID"]== ID) & (SiteLevelInfoIncludeClinStats["TOQT"] == tnum)]
       abcessdf = SiteLevelInfoIncludeClinStats.loc[(SiteLevelInfoIncludeClinStats["SUBJID"]== ID) & (SiteLevelInfoIncludeClinStats["TOQT"] == tnum)]
       bleeddf = SiteLevelInfoIncludeClinStats.loc[(SiteLevelInfoIncludeClinStats["SUBJID"]== ID) & (SiteLevelInfoIncludeClinStats["TOQT"] == tnum)]
       if 1 in tnumdf.TOMISSFN.values:
           missingteeth += 1
       if 1 in bleeddf.BOPFN.values:
           bleedingteeth+=1
       if 1 in abcessdf.ABCESSFN.values:
           abcesses += 1
    tomissfn.update({ID:missingteeth})
    abcessfn.update({ID:abcesses})
    bopfn.update({ID:bleedingteeth})

list = [tomissfn,abcessfn,bopfn]
collist = ["TMISSN","NABCESS","NBOP"]
FinalClinData = SubjectInfoInclude
x = 0
for dict in list:
    ClinValues = pd.DataFrame.from_dict(dict, orient='index',columns = [str(collist[x])])
    print(ClinValues.columns)
    FinalClinData =  FinalClinData.join(ClinValues,lsuffix="subj",rsuffix="clin")
    x+=1

#AllData = pd.concat([FinalClinData,SubjectProgressionInfo],axis=)
FinalClinData['SEXCD'] = np.where(FinalClinData["SEX"]=="Male",1,2)
FinalClinData = pd.concat([FinalClinData,PRSScores],axis=1)
AllData = FinalClinData.merge(SubjectProgressionInfo,left_index=True,right_index=True)
AllData = AllData[['ID','PDCD', 'AGE','SEXCD','ETHNCD', 'RACECD','TMISSN', 'NABCESS','NBOP','PRScs_SCORE', 'PROGCLASS']]
AllData = AllData.dropna()
AllData = AllData.astype("float32")

PRSTEST = pd.concat([PRSScores["PRSSTAN"],SubjectProgressionInfo],axis=1)
#PRSTEST = PRSTEST[PRSTEST.PROGCLASS != 2]
PRSTEST= PRSTEST.dropna()
Q = PRSTEST.iloc[:, :-1]
r = PRSTEST.iloc[:, -1]
Q_train, Q_test, r_train, r_test = train_test_split(
    Q,r,test_size=0.2, random_state=1)


def make_logreg_classifier(Q_train, Q_test, r_train, r_test, 
                        penalty = 'l2', C=1,  
                        random_state =1):
    lr = LogisticRegression(random_state = random_state, multi_class="multinomial", solver="lbfgs")
    lr.fit(Q_train, r_train)
    lr_preds = lr.predict(Q_test)
    prelr, reclr, acclr = precision_score(r_test, lr_preds,average='micro'),recall_score(r_test, lr_preds,average='micro'), lr.score(Q_test,r_test)
    
    return (prelr, reclr, acclr), lr, lr_preds

lr_scores, lr, lr_preds = make_logreg_classifier(Q_train, Q_test, r_train, r_test)
print('Logistic Regression classifier scores:')
print('Precision: {}, Recall: {}, Accuracy: {}'.format(lr_scores[0],lr_scores[1],lr_scores[2]))

features = AllData.iloc[:, :-1]
target = AllData.iloc[:, -1]
X_train, X_test, y_train, y_test = train_test_split(
    features, target, test_size=0.2, random_state=1)
features = AllData.iloc[:, :-1]
target = AllData.iloc[:, -1]
np.asarray(features)
np.asarray(target)
normalizer =  tf.keras.layers.Normalization(axis = -1)
normalizer.adapt(features)
X_train, X_test, y_train, y_test = train_test_split(
    features, target, test_size=0.2, random_state=1)

X_train,X_val,y_train,y_val = train_test_split(
    X_train,y_train,test_size=0.1,random_state=1)

y_train = np.asarray(y_train).reshape(-1,1)
y_test = np.asarray(y_test).reshape((-1,1))

input_shape = X_train.shape

print("X_train :",X_train.shape)
print("X_test:", X_test.shape)
print("X_train:", X_test.shape)
print("y_train:", y_train.shape)
print("y_test:", y_test.shape)
print("y_val:", y_val.shape)

nepochs = 20
def clf_model():
    clf = tf.keras.Sequential([
        normalizer,
        #tf.keras.layers.InputLayer(input_shape = X_train.shape),
        tf.keras.layers.Dense(10,activation ="relu"),
        tf.keras.layers.Dense(5,activation ="relu"),
        tf.keras.layers.Dense(5,activation ="relu"),
        tf.keras.layers.Dense(1,activation ="relu") 
    ])
    clf.compile( optimizer="adam", 
            loss = tf.keras.losses.BinaryCrossentropy(from_logits=True),
            metrics = (["accuracy"]))
    return clf

clf = clf_model()
history = clf.fit(X_train,y_train,epochs=nepochs,validation_split=0.25,verbose=1) # validation_split= 0.1 ,verbose=2)
plt.plot(history.history['accuracy'])
plt.title(label= "Accuracy vs. Epoch")
plt.xlabel("Epoch")
plt.xticks(np.arange(0,nepochs, step=5))
plt.ylabel("% Accuracy")
clf.evaluate(X_test,y_test,verbose=1)
clf.count_params()
