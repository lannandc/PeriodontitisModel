import tensorflow as tf
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
#from sklearn.neural_network import MLPClassifier
#from sklearn.datasets import make_classification
#from sklearn.model_selection import train_test_split
import numpy as np
import math
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras import layers
from tensorflow.keras.layers import Dense,Flatten
import matplotlib.pyplot as plt


SubjectInfo = pd.read_csv("/Users/lannacaruth/PycharmProjects/pythonProject1/Periodontitis/ads_subj_lelvel_metadata_csv.csv",dtype= {"SUBJID":str},index_col="SUBJID")
SubjectInfoInclude = SubjectInfo[SubjectInfo["COMPLEFL"]== "Y"] #remove subjects who were marked as not having completed the study
#remove dates and communication
SubjectInfoInclude.drop(["DOB","BASEDT","INFCDT","ELIGFL","ELIGDT","NOCONT","NOCNTOTH","SCRDT","MO2DT","MO4DT","MO6DT","MO8DT","MO10DT","MO12DT","PTPVDT","PTSVDT","PMO3DT","PMO6DT","COMPLEDT","DSREASCD","DSREAS","DSSPEC","LASTDT","DSCOMM"],axis=1,inplace=True)
SubjectInfoInclude.shape

PRSScores  = pd.read_excel("/Users/lannacaruth/PycharmProjects/pythonProject1/Periodontitis/Project_IFT_Microbiology (426 samples)_GWAS_Report copy.xlsx",dtype= {"Subject ID":"string"},index_col="Subject ID")
PRSScores = pd.DataFrame(PRSScores[['PRScs_SCORE']])
PRSScores["PRSSTAN"] = PRSScores.apply(lambda x:(x['PRScs_SCORE']- PRSScores['PRScs_SCORE'].mean()) / PRSScores['PRScs_SCORE'].std(),axis=1)


SerumInfo = pd.read_csv("/Users/lannacaruth/PycharmProjects/pythonProject1/Periodontitis/serum_merged copy.csv",dtype= {"Subject_ID":"string"},index_col='Subject_ID')
SerumInfo = SerumInfo[SerumInfo["Visit_number"]=="Baseline"]
SerumInfo.drop(['PDCLASS', 'progclass', 'Visit_number'],axis=1,inplace=True) #"MMP_9__14_","Human_serum_MPO__53_"])
#SerumInfo.columns


SiteLevelInfo = pd.read_csv("/Users/lannacaruth/PycharmProjects/pythonProject1/Periodontitis/adpd_periodontaldata.csv.gz") #one record per subject per visit per tooth per tooth site
SiteLevelInfoInclude = SiteLevelInfo[SiteLevelInfo["VISITN"]==0]
#remove dates and columns that were direct pull from suject level data
#SiteLevelInfoInclude.drop(["ENTERFL","PDCD","INFCDT","SEX","AGE","ETHNCD","ETHN","RACECD","RACE","ENTERFL","PHASE","VISIT","SITE","SITEID","SITENO","BASEDT","INFCDT","ELIGFL","ELIGDT","PDCD"],axis=1,inplace=True)



#select obly subject id , vist number, median pocket depth, tooth missing flags, abcess flags, tooth number, and bleeding on probing flags
toothnumbers = SiteLevelInfo["TOQT"].unique()
SiteLevelInfoIncludeClinStats = SiteLevelInfoInclude[["SUBJID","ID","VISITN","PDEP","TOMISSFN","ABCESSFN","TOQT","BOPFN"]] 
#for each id
#count values in column that are not empty
#take that number and put it in a seperate column
MouthLevelInfoIncludeClinStats = SiteLevelInfoIncludeClinStats[["SUBJID","ID"]]
SubjectProgressionInfo = pd.read_excel("/Users/lannacaruth/PycharmProjects/pythonProject1/Periodontitis/Subj_level_PDClass_ProgressionClass.xlsx",dtype={"subjid":"string"},index_col="subjid")
#remove index and initial classification columns
SubjectProgressionInfo.drop(["Obs","PDCLASS"],axis=1,inplace=True)
#match naming and type converntions in subject level data frame
SubjectProgressionInfo.rename(columns={"progclass":"PROGCLASS"},inplace=True)

#creating mouth level stats
tomissfn ={}
abcessfn ={}
bopfn ={}
for ID in SubjectInfoInclude.index: 
    missingteeth = 0
    abcesses = 0
    bleedingteeth = 0
    for tnum in toothnumbers:
       tnumdf = SiteLevelInfoIncludeClinStats.loc[(SiteLevelInfoIncludeClinStats["SUBJID"]== ID) & (SiteLevelInfoIncludeClinStats["TOQT"] == tnum)]
       abcessdf = SiteLevelInfoIncludeClinStats.loc[(SiteLevelInfoIncludeClinStats["SUBJID"]== ID) & (SiteLevelInfoIncludeClinStats["TOQT"] == tnum)]
       bleeddf = SiteLevelInfoIncludeClinStats.loc[(SiteLevelInfoIncludeClinStats["SUBJID"]== ID) & (SiteLevelInfoIncludeClinStats["TOQT"] == tnum)]
       if 1 in tnumdf.TOMISSFN.values:
           missingteeth += 1
       if 1 in bleeddf.BOPFN.values:
           bleedingteeth+=1
       if 1 in abcessdf.ABCESSFN.values:
           abcesses += 1
    tomissfn.update({ID:missingteeth})
    #tomissfn.update({ID:missingteeth})
    abcessfn.update({ID:abcesses})
    bopfn.update({ID:bleedingteeth})

list = [tomissfn,abcessfn,bopfn]
collist = ["TMISSN","NABCESS","NBOP"]
FinalClinData = pd.concat([SubjectInfoInclude,SerumInfo],axis=1)
x = 0
for dict in list:
    ClinValues = pd.DataFrame.from_dict(dict, orient='index',columns = [str(collist[x])])
    print(ClinValues.columns)
    FinalClinData =  FinalClinData.join(ClinValues,lsuffix="subj",rsuffix="clin")
    x+=1

#AllData = pd.concat([FinalClinData,SubjectProgressionInfo],axis=)
FinalClinData['SEXCD'] = np.where(FinalClinData["SEX"]=="Male",1,2)
FinalClinData = pd.concat([FinalClinData,PRSScores],axis=1) 
AllData = FinalClinData.merge(SubjectProgressionInfo,left_index=True,right_index=True)
#AllData = AllData[['ID','PDCD','SCELIGFL', 'PDCLASS', 'THERFL', 'COMPLEFL', 'SEX', 'AGE','ETHNCD', 'RACECD', 'TMISSN', 'NABCESS','NBOP', 'PROGCLASS']]
AllData = AllData[['ID','PDCD', 'AGE','SEXCD','ETHNCD', 'RACECD','TMISSN', 'NABCESS','NBOP','Human_Serum_Amyloid_A1__21_', 'CRP__62_', 'MMP_8__27_', 'MMP_9__14_',
       'Human_serum_MPO__53_','PRScs_SCORE','PROGCLASS']]
AllData['PROGCLASS'].replace(1,0,inplace=True)
AllData['PROGCLASS'].replace(2,1,inplace=True)
AllData = AllData.dropna()
AllData = AllData.astype("float32")

PRSTEST = pd.concat([PRSScores["PRSSTAN"],SubjectProgressionInfo],axis=1)
#PRSTEST = PRSTEST[PRSTEST.PROGCLASS != 2]
PRSTEST= PRSTEST.dropna()
Q = PRSTEST.iloc[:, :-1]
r = PRSTEST.iloc[:, -1]
Q_train, Q_test, r_train, r_test = train_test_split(
    Q,r,test_size=0.2, random_state=1)

from sklearn.linear_model import LogisticRegression
from sklearn.datasets import make_classification
from sklearn.model_selection import cross_val_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
def make_logreg_classifier(Q_train, Q_test, r_train, r_test, 
                        penalty = 'l2', C=1,  
                        random_state =1):
    lr = LogisticRegression(random_state = random_state, multi_class="multinomial", solver="lbfgs")
    lr.fit(Q_train, r_train)
    lr_preds = lr.predict(Q_test)
    prelr, reclr, acclr = precision_score(r_test, lr_preds,average='micro'),recall_score(r_test, lr_preds,average='micro'), lr.score(Q_test,r_test)
    
    return (prelr, reclr, acclr), lr, lr_preds

lr_scores, lr, lr_preds = make_logreg_classifier(Q_train, Q_test, r_train, r_test)
print('Logistic Regression classifier scores:')
print('Precision: {}, Recall: {}, Accuracy: {}'.format(lr_scores[0],lr_scores[1],lr_scores[2]))


features = AllData.iloc[:, :-1]
target = AllData.iloc[:, -1]
np.asarray(features)
np.asarray(target)
normalizer =  tf.keras.layers.Normalization(axis = -1)
normalizer.adapt(features)
X_train, X_test, y_train, y_test = train_test_split(
    features, target, test_size=0.2, random_state=1)

X_train,X_val,y_train,y_val = train_test_split(
    X_train,y_train,test_size=0.1,random_state=1)

y_train = np.asarray(y_train).reshape(-1,1)
y_test = np.asarray(y_test).reshape((-1,1))

input_shape = X_train.shape

print("X_train :",X_train.shape)
print("X_test:", X_test.shape)
print("X_train:", X_test.shape)
print("y_train:", y_train.shape)
print("y_test:", y_test.shape)
print("y_val:", y_val.shape)

nepochs = 20
def clf_model():
    clf = tf.keras.Sequential([
        normalizer,
        #tf.keras.layers.InputLayer(input_shape = X_train.shape),
        tf.keras.layers.Dense(10,activation ="relu"),
        tf.keras.layers.Dense(5,activation ="relu"),
        tf.keras.layers.Dense(5,activation ="relu"),
        tf.keras.layers.Dense(1,activation ="relu") 
    ])
    clf.compile( optimizer="adam", 
            loss = tf.keras.losses.BinaryCrossentropy(from_logits=True),
            metrics = (["accuracy"]))
    return clf

clf = clf_model()
history = clf.fit(X_train,y_train,epochs=nepochs,validation_split=0.25,verbose=1) # validation_split= 0.1 ,verbose=2)
plt.plot(history.history['accuracy'])
plt.title(label= "Accuracy vs. Epoch")
plt.xlabel("Epoch")
plt.xticks(np.arange(0,nepochs, step=5))
plt.ylabel("% Accuracy")
clf.evaluate(X_test,y_test,verbose=1)


